{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cardinality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learned that when we are dealing with categorical variables, their categories are often called labels. We call the cardinality of a categorical variable the number of labels it has. For example, if the variable we are dealing with corresponds to a person's gender, it will have cardinality 2: man and woman. If the variable we are working on concerns cities, it can have a very high cardinality, since the variable can take on different values such as London, Rio de Janeiro, Tokyo, New York, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will explore issue of cardinality with the aim of approaching it from the following aspects: \n",
    "- Show how the presence of categorical variables with high cardinality can harm machine learning models, mainly those based on decision trees;\n",
    "- In tree-based models, the presence of categorical variables with high cardinality introduce a high bias in the model decisions, since the number of classes present in these variables is much higher than that of variables with lower cardinality;\n",
    "- The presence of variables with high cardinality increases the chances of a subset of the labels only being present in the training data or test data;\n",
    "- If a subset of the labels is only present in the training data, this causes the model to tend to overfitting, since it will learn the behavior of these labels in training but they are not present in the test set;\n",
    "- If a subset of the labels is only present in the test data, the model's performance will be harmed, since it will deal with categories on which it was not trained;\n",
    "- Show that creating variables with low cardinality from those with high cardinality improves the model's performance and is a good practice to be carried out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================================================================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-On: Titanic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore the cardinality of categorical variables, we will work with the Titanic dataset. Let's start by observing the cardinality of the categorical variables present in it and, after that, reduce the cardinality in those that have a high cardinality by creating new variables from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# scikit-learn train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# scikit-learn classifier models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# scikit-learn metric to evaluate the performance\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375    B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500   C22        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500   C22        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500   C22        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500   C22        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the titanic dataset\n",
    "path_titanic = '../datasets/titanic.csv'\n",
    "titanic_df = pd.read_csv(path_titanic)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical variables in this dataset are: `sex`, `ticket`, `cabin` and `embarked`. The variables `cabin` and `ticket` involve both letters and numbers and can be included in the mixed variable type, which we have already discussed in the previous section. However, at this point we will treat them as categorical variables. Let's check the cardinality of each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of names in Titanic: 1307\n",
      "Number of unique labels of sex variable: 2\n",
      "Number of unique labels of ticket variable: 929\n",
      "Number of unique labels of cabin variable: 182\n",
      "Number of unique labels of embarked variable: 4\n",
      "Number of passengers in Titanic: 1309\n"
     ]
    }
   ],
   "source": [
    "# verifying the cardinality of these categorical features\n",
    "print(f\"Number of names in Titanic: {len(titanic_df.name.unique())}\")\n",
    "print(f\"Number of unique labels of sex variable: {len(titanic_df.sex.unique())}\") # sex\n",
    "print(f\"Number of unique labels of ticket variable: {len(titanic_df.ticket.unique())}\") # ticket\n",
    "print(f\"Number of unique labels of cabin variable: {len(titanic_df.cabin.unique())}\") # cabin \n",
    "print(f\"Number of unique labels of embarked variable: {len(titanic_df.embarked.unique())}\") # embarked\n",
    "print(f\"Number of passengers in Titanic: {len(titanic_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is clear that some variables have low cardinality - `sex` and `embarked` - and others have high cardinality - `ticket` and `cabin`. Let's work with the `cabin` variable and look at the number of distinct labels it has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B5', 'C22', 'E12', 'D7', 'A36', 'C101', nan, 'C62', 'B35', 'A23',\n",
       "       'B58', 'D15', 'C6', 'D35', 'C148', 'C97', 'B49', 'C99', 'C52', 'T',\n",
       "       'A31', 'C7', 'C103', 'D22', 'E33', 'A21', 'B10', 'B4', 'E40',\n",
       "       'B38', 'E24', 'B51', 'B96', 'C46', 'E31', 'E8', 'B61', 'B77', 'A9',\n",
       "       'C89', 'A14', 'E58', 'E49', 'E52', 'E45', 'B22', 'B26', 'C85',\n",
       "       'E17', 'B71', 'B20', 'A34', 'C86', 'A16', 'A20', 'A18', 'C54',\n",
       "       'C45', 'D20', 'A29', 'C95', 'E25', 'C111', 'C23', 'E36', 'D34',\n",
       "       'D40', 'B39', 'B41', 'B102', 'C123', 'E63', 'C130', 'B86', 'C92',\n",
       "       'A5', 'C51', 'B42', 'C91', 'C125', 'D10', 'B82', 'E50', 'D33',\n",
       "       'C83', 'B94', 'D49', 'D45', 'B69', 'B11', 'E46', 'C39', 'B18',\n",
       "       'D11', 'C93', 'B28', 'C49', 'B52', 'E60', 'C132', 'B37', 'D21',\n",
       "       'D19', 'C124', 'D17', 'B101', 'D28', 'D6', 'D9', 'B80', 'C106',\n",
       "       'B79', 'C47', 'D30', 'C90', 'E38', 'C78', 'C30', 'C118', 'D36',\n",
       "       'D48', 'D47', 'C105', 'B36', 'B30', 'D43', 'B24', 'C2', 'C65',\n",
       "       'B73', 'C104', 'C110', 'C50', 'B3', 'A24', 'A32', 'A11', 'A10',\n",
       "       'B57', 'C28', 'E44', 'A26', 'A6', 'A7', 'C31', 'A19', 'B45', 'E34',\n",
       "       'B78', 'B50', 'C87', 'C116', 'C55', 'D50', 'E68', 'E67', 'C126',\n",
       "       'C68', 'C70', 'C53', 'B19', 'D46', 'D37', 'D26', 'C32', 'C80',\n",
       "       'C82', 'C128', 'E39', 'D', 'F4', 'D56', 'F33', 'E101', 'E77', 'F2',\n",
       "       'D38', 'F', 'E121', 'E10', 'G6', 'F38'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique categories present on cabin feature\n",
    "titanic_df.cabin.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea now will be to reduce this cardinality by creating a new variable from it using only the first letter of the labels. The variable concerns the sectors of the rooms where people stayed on the Titanic. The letters in the acronym correspond to the separation in terms of price class. Therefore, it makes sense to use only the letters to create a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new variable from cabin to reduce cardinality\n",
    "titanic_df['cabin_reduced'] = titanic_df.cabin.astype(str).str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us verify the cardinality of this new variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels for cabin reduced variable: 9\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique labels for cabin reduced variable: {len(titanic_df.cabin_reduced.unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to reduce the cardinality from $182$ to $9$ using this new variable. As we will see later, using the variable with the highest cardinality will harm our machine learning model while the variable with the lowest cardinality that we just created will help it. Before that, however, let's show how high cardinality can harm our training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Cardinality creates uneven distribution of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that our data consists only of the variables `cabin`, `cabin_reduced` and `sex`, in addition to the target `survived`, of course. Let's create the training and test set from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training and test sets from this subset of features\n",
    "features_subset = ['cabin', 'cabin_reduced', 'sex']\n",
    "\n",
    "# splitting the data in train and test sets\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    train_test_split(\n",
    "        titanic_df[features_subset],\n",
    "        titanic_df['survived'],\n",
    "        test_size=0.3,\n",
    "        random_state=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is interesting to do the following analysis: see how many of the labels for the variables `cabin` and `cabin_reduced` are found in the training data and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of labels which are in train set and not in test set - cabin feature\n",
    "labels_in_train = [\n",
    "    label for label in X_train.cabin.unique() if label not in X_test.cabin.unique()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of this set\n",
    "len(labels_in_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the $182$ categories, $113$ is found in the training set only! As we will see, this will cause overfitting in our models. Let's see how many categories are present in the test set but not in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of labels which are in test set and not in train set - cabin feature\n",
    "labels_in_test = [\n",
    "    label for label in X_test.cabin.unique() if label not in X_train.cabin.unique()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of this set\n",
    "len(labels_in_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem also occurs here. $36$ categories of the `cabin` variable are only present in the test set. This means that, when we train a model, it will not have learned these labels and will cause its performance to decline. So high cardinality is indeed a problem. Let's check if we use the variable `cabin_reduced` this problem is reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of labels which are in train set and not in test set - cabin_reduced feature\n",
    "labels_in_train = [\n",
    "    label for label in X_train.cabin_reduced.unique() if label not in X_test.cabin_reduced.unique()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of this set\n",
    "len(labels_in_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very good! Only one label of the variable `cabin_reduced` is present in the training set and not in the test set. Let's check how many are present in the test set alone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of labels which are in test set and not in train set - cabin_reduced feature\n",
    "labels_in_test = [\n",
    "    label for label in X_test.cabin_reduced.unique() if label not in X_train.cabin_reduced.unique()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of this set\n",
    "len(labels_in_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, all labels present in the test set are present in the training set! In other words, by using a variable with reduced cardinality, we are able to avoid the problems of uneven distribution of classes between the training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of Cardinality on the Performance of Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next task is to verify the impact of cardinality on the performance of machine learning models. As we know, scikit-learn machine learning models do not work with variables in string format and must be numeric. Therefore, we first need to create a dictionary to map the labels of the variables `cabin` and `cabin_reduced` into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary for cabin feature from X_train\n",
    "dict_cabin = {\n",
    "    i: j for j, i in enumerate(X_train.cabin.unique(), 0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary for cabin_reduced feature from X_train\n",
    "dict_cabin_reduced = {\n",
    "    i: j for j, i in enumerate(X_train.cabin_reduced.unique())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use them to actually map the variables `cabin` and `cabin_reduced` into numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping cabin and cabin_reduced into numbers\n",
    "X_train.loc[:, 'cabin_mapped'] = X_train.loc[:, 'cabin'].map(dict_cabin)\n",
    "X_test.loc[:, 'cabin_mapped'] = X_test.loc[:, 'cabin'].map(dict_cabin)\n",
    "X_train.loc[:, 'cabin_reduced_mapped'] = X_train.loc[:, 'cabin_reduced'].map(dict_cabin_reduced)\n",
    "X_test.loc[:, 'cabin_reduced_mapped'] = X_test.loc[:, 'cabin_reduced'].map(dict_cabin_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cabin</th>\n",
       "      <th>cabin_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>E36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>C68</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>E24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cabin  cabin_mapped\n",
       "501    NaN             0\n",
       "588    NaN             0\n",
       "402    NaN             0\n",
       "1193   NaN             0\n",
       "686    NaN             0\n",
       "971    NaN             0\n",
       "117    E36             1\n",
       "540    NaN             0\n",
       "294    C68             2\n",
       "261    E24             3\n",
       "587    NaN             0\n",
       "489    NaN             0\n",
       "2      C22             4\n",
       "405    NaN             0\n",
       "1284   NaN             0\n",
       "338    NaN             0\n",
       "356    NaN             0\n",
       "985    NaN             0\n",
       "182    NaN             0\n",
       "1027   NaN             0\n",
       "1023   NaN             0\n",
       "657    NaN             0\n",
       "891    NaN             0\n",
       "716    NaN             0\n",
       "1142   NaN             0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['cabin', 'cabin_mapped']].head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cabin_reduced</th>\n",
       "      <th>cabin_reduced_mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cabin_reduced  cabin_reduced_mapped\n",
       "501              n                     0\n",
       "588              n                     0\n",
       "402              n                     0\n",
       "1193             n                     0\n",
       "686              n                     0\n",
       "971              n                     0\n",
       "117              E                     1\n",
       "540              n                     0\n",
       "294              C                     2\n",
       "261              E                     1\n",
       "587              n                     0\n",
       "489              n                     0\n",
       "2                C                     2\n",
       "405              n                     0\n",
       "1284             n                     0\n",
       "338              n                     0\n",
       "356              n                     0\n",
       "985              n                     0\n",
       "182              n                     0\n",
       "1027             n                     0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['cabin_reduced', 'cabin_reduced_mapped']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that we can correctly map the variables `cabin` and `cabin_reduced` into numeric values. Let's now map the variable `sex` into numeric values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping sex feature into numerical one\n",
    "X_train.loc[:, 'sex'] = X_train.loc[:, 'sex'].map({'male': 0, 'female': 1})\n",
    "X_test.loc[:, 'sex'] = X_test.loc[:, 'sex'].map({'male': 0, 'female': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to check that there are no more null values in the training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cabin_mapped            0\n",
       "cabin_reduced_mapped    0\n",
       "sex                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing if there are null values in X_train for mapped features\n",
    "X_train[['cabin_mapped', 'cabin_reduced_mapped', 'sex']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cabin_mapped            41\n",
       "cabin_reduced_mapped     0\n",
       "sex                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing if there are null values in X_test for mapped features\n",
    "X_test[['cabin_mapped', 'cabin_reduced_mapped', 'sex']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data does not contain null values, as expected. However, for the test set there are $41$ null values in the `cabin_mapped` variable. This occurred because when we created the dictionary that performs the mapping we used the `X_train` set to create the map, and, as we saw, there are labels that are only present in the test set. Therefore, the mapping does not work for these labels - since they are not present in the dictionary - and they end up receiving null values. For these cases, we will set it to $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model we will train will be a Random Forest. The idea is to show how the presence of high cardinality changes the model's predictions. We will use ROCAUC as a metric. First, we will carry out the training using the variable `cabin_mapped`, which has high cardinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a random forest classifier using cabin_mapped feature\n",
    "\n",
    "# random forest model\n",
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=31,\n",
    ")\n",
    "\n",
    "# fitting\n",
    "random_forest.fit(\n",
    "    X_train[['cabin_mapped', 'sex']], \n",
    "    y_train\n",
    ")\n",
    "\n",
    "# predictions on train and test sets\n",
    "predictions_train = random_forest.predict_proba(\n",
    "    X_train[['cabin_mapped', 'sex']]\n",
    ")\n",
    "predictions_test = random_forest.predict_proba(\n",
    "    X_test[['cabin_mapped', 'sex']].fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the results by calculating ROCAUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "The ROCAUC for the model tested on trained data is: 0.854\n",
      "Test Set:\n",
      "The ROCAUC for the model tested on test data is: 0.773\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set:\")\n",
    "print(f\"The ROCAUC for the model tested on trained data is: {np.round(roc_auc_score(y_train, predictions_train[:,1]), 3)}\")\n",
    "print(\"Test Set:\")\n",
    "print(f\"The ROCAUC for the model tested on test data is: {np.round(roc_auc_score(y_test, predictions_test[:,1]), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the performance is different in the two scenarios, being significantly higher in the training data, which indicates the presence of overfitting. Let's now use the variable `cabin_reduced_mapped`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a random forest classifier using cabin_reduced_mapped feature\n",
    "\n",
    "# random forest model\n",
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=31,\n",
    ")\n",
    "\n",
    "# fitting\n",
    "random_forest.fit(\n",
    "    X_train[['cabin_reduced_mapped', 'sex']], \n",
    "    y_train\n",
    ")\n",
    "\n",
    "# predictions on train and test sets\n",
    "predictions_train = random_forest.predict_proba(\n",
    "    X_train[['cabin_reduced_mapped', 'sex']]\n",
    ")\n",
    "predictions_test = random_forest.predict_proba(\n",
    "    X_test[['cabin_reduced_mapped', 'sex']].fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "The ROCAUC for the model tested on trained data is: 0.816\n",
      "Test Set:\n",
      "The ROCAUC for the model tested on test data is: 0.802\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set:\")\n",
    "print(f\"The ROCAUC for the model tested on trained data is: {np.round(roc_auc_score(y_train, predictions_train[:,1]), 3)}\")\n",
    "print(\"Test Set:\")\n",
    "print(f\"The ROCAUC for the model tested on test data is: {np.round(roc_auc_score(y_test, predictions_test[:,1]), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is no longer any overfitting. The performance in both sets was the same. This indicates that decreasing the cardinality improves the performance of the models. Let's repeat the procedure for an AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a adaboost classifier using cabin_mapped feature\n",
    "\n",
    "# random forest model\n",
    "adaboost = AdaBoostClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=32,\n",
    ")\n",
    "\n",
    "# fitting\n",
    "adaboost.fit(\n",
    "    X_train[['cabin_mapped', 'sex']], \n",
    "    y_train\n",
    ")\n",
    "\n",
    "# predictions on train and test sets\n",
    "predictions_train = adaboost.predict_proba(\n",
    "    X_train[['cabin_mapped', 'sex']]\n",
    ")\n",
    "predictions_test = adaboost.predict_proba(\n",
    "    X_test[['cabin_mapped', 'sex']].fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the results by calculating ROCAUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "The ROCAUC for the model tested on trained data is: 0.83\n",
      "Test Set:\n",
      "The ROCAUC for the model tested on test data is: 0.76\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set:\")\n",
    "print(f\"The ROCAUC for the model tested on trained data is: {np.round(roc_auc_score(y_train, predictions_train[:,1]), 3)}\")\n",
    "print(\"Test Set:\")\n",
    "print(f\"The ROCAUC for the model tested on test data is: {np.round(roc_auc_score(y_test, predictions_test[:,1]), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, there is the presence of overfitting in the training data. Let's see what happens when we use the `cabin_reduced_mapped` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a adaboost using cabin_reduced_mapped feature\n",
    "\n",
    "# adaboost\n",
    "adaboost = AdaBoostClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=32,\n",
    ")\n",
    "\n",
    "# fitting\n",
    "adaboost.fit(\n",
    "    X_train[['cabin_reduced_mapped', 'sex']], \n",
    "    y_train\n",
    ")\n",
    "\n",
    "# predictions on train and test sets\n",
    "predictions_train = adaboost.predict_proba(\n",
    "    X_train[['cabin_reduced_mapped', 'sex']]\n",
    ")\n",
    "predictions_test = adaboost.predict_proba(\n",
    "    X_test[['cabin_reduced_mapped', 'sex']].fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "The ROCAUC for the model tested on trained data is: 0.816\n",
      "Test Set:\n",
      "The ROCAUC for the model tested on test data is: 0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set:\")\n",
    "print(f\"The ROCAUC for the model tested on trained data is: {np.round(roc_auc_score(y_train, predictions_train[:,1]), 3)}\")\n",
    "print(\"Test Set:\")\n",
    "print(f\"The ROCAUC for the model tested on test data is: {np.round(roc_auc_score(y_test, predictions_test[:,1]), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, performance improves. In other words, overfitting is overcome by using a variable with a lower cardinality. Let's repeat the same procedure for a logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a logistic regression using cabin_mapped feature\n",
    "\n",
    "# logistic regression\n",
    "logit = LogisticRegression(\n",
    "    solver='lbfgs',\n",
    "    random_state=33,\n",
    ")\n",
    "\n",
    "# fitting\n",
    "logit.fit(\n",
    "    X_train[['cabin_mapped', 'sex']], \n",
    "    y_train\n",
    ")\n",
    "\n",
    "# predictions on train and test sets\n",
    "predictions_train = logit.predict_proba(\n",
    "    X_train[['cabin_mapped', 'sex']]\n",
    ")\n",
    "predictions_test = logit.predict_proba(\n",
    "    X_test[['cabin_mapped', 'sex']].fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the results by calculating ROCAUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "The ROCAUC for the model tested on trained data is: 0.813\n",
      "Test Set:\n",
      "The ROCAUC for the model tested on test data is: 0.775\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set:\")\n",
    "print(f\"The ROCAUC for the model tested on trained data is: {np.round(roc_auc_score(y_train, predictions_train[:,1]), 3)}\")\n",
    "print(\"Test Set:\")\n",
    "print(f\"The ROCAUC for the model tested on test data is: {np.round(roc_auc_score(y_test, predictions_test[:,1]), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, overfitting the training data. Performance will possibly improve when using `cabin_reduced_mapped`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a logistic regression using cabin_reduced_mapped feature\n",
    "\n",
    "# logistic regression\n",
    "logit = LogisticRegression(\n",
    "    solver='lbfgs',\n",
    "    random_state=33,\n",
    ")\n",
    "\n",
    "# fitting\n",
    "logit.fit(\n",
    "    X_train[['cabin_reduced_mapped', 'sex']], \n",
    "    y_train\n",
    ")\n",
    "\n",
    "# predictions on train and test sets\n",
    "predictions_train = logit.predict_proba(\n",
    "    X_train[['cabin_reduced_mapped', 'sex']]\n",
    ")\n",
    "predictions_test = logit.predict_proba(\n",
    "    X_test[['cabin_reduced_mapped', 'sex']].fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "The ROCAUC for the model tested on trained data is: 0.812\n",
      "Test Set:\n",
      "The ROCAUC for the model tested on test data is: 0.801\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set:\")\n",
    "print(f\"The ROCAUC for the model tested on trained data is: {np.round(roc_auc_score(y_train, predictions_train[:,1]), 3)}\")\n",
    "print(\"Test Set:\")\n",
    "print(f\"The ROCAUC for the model tested on test data is: {np.round(roc_auc_score(y_test, predictions_test[:,1]), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that is what happens, as we expected. Lastly, let's test Gradient Boosting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a gradient boosting classifier using cabin_mapped feature\n",
    "\n",
    "# gradient boosting classifier\n",
    "gradient_boosting = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=34,\n",
    ")\n",
    "\n",
    "# fitting\n",
    "gradient_boosting.fit(\n",
    "    X_train[['cabin_mapped', 'sex']], \n",
    "    y_train\n",
    ")\n",
    "\n",
    "# predictions on train and test sets\n",
    "predictions_train = gradient_boosting.predict_proba(\n",
    "    X_train[['cabin_mapped', 'sex']]\n",
    ")\n",
    "predictions_test = gradient_boosting.predict_proba(\n",
    "    X_test[['cabin_mapped', 'sex']].fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the results by calculating ROCAUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "The ROCAUC for the model tested on trained data is: 0.859\n",
      "Test Set:\n",
      "The ROCAUC for the model tested on test data is: 0.777\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set:\")\n",
    "print(f\"The ROCAUC for the model tested on trained data is: {np.round(roc_auc_score(y_train, predictions_train[:,1]), 3)}\")\n",
    "print(\"Test Set:\")\n",
    "print(f\"The ROCAUC for the model tested on test data is: {np.round(roc_auc_score(y_test, predictions_test[:,1]), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, there is the presence of overfitting in the training data. Let's see what happens when we use the `cabin_reduced_mapped` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a gradient boosting using cabin_reduced_mapped feature\n",
    "\n",
    "# gradient boosting classifier\n",
    "gradient_boosting = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=34,\n",
    ")\n",
    "\n",
    "# fitting\n",
    "gradient_boosting.fit(\n",
    "    X_train[['cabin_reduced_mapped', 'sex']], \n",
    "    y_train\n",
    ")\n",
    "\n",
    "# predictions on train and test sets\n",
    "predictions_train = gradient_boosting.predict_proba(\n",
    "    X_train[['cabin_reduced_mapped', 'sex']]\n",
    ")\n",
    "predictions_test = gradient_boosting.predict_proba(\n",
    "    X_test[['cabin_reduced_mapped', 'sex']].fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "The ROCAUC for the model tested on trained data is: 0.817\n",
      "Test Set:\n",
      "The ROCAUC for the model tested on test data is: 0.802\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set:\")\n",
    "print(f\"The ROCAUC for the model tested on trained data is: {np.round(roc_auc_score(y_train, predictions_train[:,1]), 3)}\")\n",
    "print(\"Test Set:\")\n",
    "print(f\"The ROCAUC for the model tested on test data is: {np.round(roc_auc_score(y_test, predictions_test[:,1]), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, using a variable with a lower cardinality reduces overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feature_engineering_for_machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
