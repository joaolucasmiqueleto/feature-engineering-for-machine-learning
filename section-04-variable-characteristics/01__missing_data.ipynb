{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will discuss missing values. The presence of missing values is common in real datasets, occurring for various reasons. It is crucial to understand their sources because if not treated correctly, they can adversely impact the predictions of machine learning models. We will explore some sources of missing values in datasets. Subsequently, we will delve into three missing data mechanisms:\n",
    "- Missing Completely at Random (MCAR);\n",
    "- Missing at Random (MAR);\n",
    "- Missing Not at Random (MNAR).\n",
    "\n",
    "Each of these mechanisms originates from different sources, and the approach to handling missing values varies for each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Reasons for Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various reasons why missing values exist. For instance, consider the scenario of completing a form that prompts the users to provide diverse information about themselves. It is common in these situations that a significant amount of information remains unfilled, either because it is not strictly necessary or because the user chooses not to disclose the requested information, among other reasons. In some instances, missing values arise due to the absence of the requested data; for instance, if a user is asked to input \"The total debt as a percentage of salary,\" and the user is unemployed, it will result in no salary. In such cases, a missing value occurs during the completion process.\n",
    "\n",
    "Therefore, it is crucial to comprehend the reasons behind the presence of missing data in the database, that is, understanding the source that generated it. Different scenarios necessitate distinct approaches to regulate and diminish missing values, showing the importance of understanding how to effectively address them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data Mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **three** mechanisms that generate missing data, and we will discuss all three next. Two of them are random, and one is systematic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Completely at Random (MCAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A missing data is considered to be **missing completely at random** if the probability of any other data also being missing is exactly equal. In other words, the subset of missing data within a dataset is entirely random. This type of missing data does not introduce bias into the inferences made when it is removed from the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing at Random (MAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data is considered to be **missing at random** when the probability of its absence is associated with other information in the dataset. In other words, the absence of information in a particular variable cannot be explained by the variable itself but by other variables in the dataset. For instance, consider a survey where individuals are required to provide their weight on the form. It may be observed that men are more likely to provide this information compared to women. Consequently, the weight is missing at random, resulting in a higher number of missing values for women than for men. In such cases, the subset with missing data is no longer random due to its association with gender.\n",
    "\n",
    "Therefore, if the intention is to retain missing data in the analysis, it is imperative to include the gender variable to mitigate bias in the analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Not at Random (MNAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A missing data is considered to be **missing not at random** if there is a specific reason or mechanism for its absence. In such cases, the probability of missing data is related to the variables themselves, with some underlying mechanism causing the absence of values. For instance, let's consider a scenario where a form requires individuals to disclose whether or not they have depression. It is plausible that many individuals with depression may choose not to reveal this information due to discomfort, leading to the non-completion of this particular section.\n",
    "\n",
    "When dealing with a subset of data that is missing not at random, it is crucial to employ appropriate techniques for handling such cases. Failure to do so may introduce significant bias into the analysis, resulting in inaccurate conclusions and findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=========================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-On: Mechanisms of Missing Data in Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea now is to identify the mechanisms discussed above in real datasets. Initially, we will analyze the famous Titanic dataset and subsequently revisit the dataset from the peer-to-peer finance company, which was previously explored in the preceding section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing basic libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# To display all columns in the dataframe\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading both datasets\n",
    "path_titanic = '../datasets/titanic.csv'\n",
    "path_peer_to_peer = '../datasets/loan.csv'\n",
    "\n",
    "titanic_df = pd.read_csv(path_titanic)\n",
    "peer_to_peer_df = pd.read_csv(path_peer_to_peer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by examining the number of null values in both dataframes. This check can be accomplished using the `isnull()` method, followed by the `sum()` method. The `sum()` method will sum the number of null values for each column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass          0\n",
       "survived        0\n",
       "name            0\n",
       "sex             0\n",
       "age           263\n",
       "sibsp           0\n",
       "parch           0\n",
       "ticket          0\n",
       "fare            1\n",
       "cabin        1014\n",
       "embarked        2\n",
       "boat          823\n",
       "body         1188\n",
       "home.dest     564\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying the number of nulls for each column - titanic dataset\n",
    "titanic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All null values are present on `age`, `cabin`, `embarked`, `boat`, `body`, and `home.dest` variables. We can verify the null percentage for each of these variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass       0.000000\n",
       "survived     0.000000\n",
       "name         0.000000\n",
       "sex          0.000000\n",
       "age          0.200917\n",
       "sibsp        0.000000\n",
       "parch        0.000000\n",
       "ticket       0.000000\n",
       "fare         0.000764\n",
       "cabin        0.774637\n",
       "embarked     0.001528\n",
       "boat         0.628724\n",
       "body         0.907563\n",
       "home.dest    0.430863\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying the percentage of null for each variable - titanic dataset\n",
    "titanic_df.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the variable `age`, $20\\%$ of the data is missing. For the variable `cabin` this value is $77\\%$, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id                  0\n",
       "disbursed_amount             0\n",
       "interest                     0\n",
       "market                       0\n",
       "employment                 611\n",
       "time_employed              529\n",
       "householder                  0\n",
       "income                       0\n",
       "date_issued                  0\n",
       "target                       0\n",
       "loan_purpose                 0\n",
       "number_open_accounts         0\n",
       "date_last_payment            0\n",
       "number_credit_lines_12    9762\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying the number of nulls for each column - peer to peer dataset\n",
    "peer_to_peer_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, all null values are found in three variables, namely, `employment`, `time_employed` and `number_credit_lines_12`. The percentage of null in each of them is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id               0.0000\n",
       "disbursed_amount          0.0000\n",
       "interest                  0.0000\n",
       "market                    0.0000\n",
       "employment                0.0611\n",
       "time_employed             0.0529\n",
       "householder               0.0000\n",
       "income                    0.0000\n",
       "date_issued               0.0000\n",
       "target                    0.0000\n",
       "loan_purpose              0.0000\n",
       "number_open_accounts      0.0000\n",
       "date_last_payment         0.0000\n",
       "number_credit_lines_12    0.9762\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying the percentage of nulls for each variable - peer to peer dataset\n",
    "peer_to_peer_df.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the variables `employment` and `time_employed` the percentage of null values is very close, corresponding to $6\\%$ and $5\\%$, respectively. As we will see, these null values have a relationship with each other. The variable `number_credit_lines_12` has $97\\%$ of the data as null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Missing Data Completely At Random (MCAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed before, a variable that has null values will be considered MCAR if the absence of its values has no relationship with any other variable and also no underlying mechanism. In other words, it is completely random. Let's analyze the `embarked` variable in the Titanic dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cincinatti, OH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass  survived                                       name     sex  \\\n",
       "168       1         1                        Icard, Miss. Amelie  female   \n",
       "284       1         1  Stone, Mrs. George Nelson (Martha Evelyn)  female   \n",
       "\n",
       "      age  sibsp  parch  ticket  fare cabin embarked boat  body  \\\n",
       "168  38.0      0      0  113572  80.0   B28      NaN    6   NaN   \n",
       "284  62.0      0      0  113572  80.0   B28      NaN    6   NaN   \n",
       "\n",
       "          home.dest  \n",
       "168             NaN  \n",
       "284  Cincinatti, OH  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the null values for embarked variable on Titanic dataset\n",
    "titanic_df[titanic_df['embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the two null values in the `embarked` variable. Note that both correspond to the same ticket and possibly boarded together. Furthermore, both survived and, therefore, this information could have been collected later - and even could have been and was just not populated in the dataset.\n",
    "\n",
    "It is likely that this missing data falls into the category of **missing data completely at random** and, in this case, the probability of it appearing for anyone else in the dataset should be the same. However, with this information alone it is impossible to prove this statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Missing Data At Random (MAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned, a variable that has null values is considered MAR if the absence of its values does not concern the variable itself, but rather depends on another (or other) variables in the data set. To explore this case, let's look at the `employment` and `time_employed` variables present in the peer-to-peer dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by filtering just these two variables in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employment</th>\n",
       "      <th>time_employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Teacher</td>\n",
       "      <td>&lt;=5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accountant</td>\n",
       "      <td>&lt;=5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Statistician</td>\n",
       "      <td>&lt;=5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Other</td>\n",
       "      <td>&lt;=5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bus driver</td>\n",
       "      <td>&gt;5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Statistician</td>\n",
       "      <td>&gt;5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Secretary</td>\n",
       "      <td>&gt;5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Software developer</td>\n",
       "      <td>&lt;=5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Statistician</td>\n",
       "      <td>&gt;5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nurse</td>\n",
       "      <td>&gt;5 years</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           employment time_employed\n",
       "0             Teacher     <=5 years\n",
       "1          Accountant     <=5 years\n",
       "2        Statistician     <=5 years\n",
       "3               Other     <=5 years\n",
       "4          Bus driver      >5 years\n",
       "5        Statistician      >5 years\n",
       "6           Secretary      >5 years\n",
       "7  Software developer     <=5 years\n",
       "8        Statistician      >5 years\n",
       "9               Nurse      >5 years"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering the data only by employment and time_employed\n",
    "peer_to_peer_df[['employment', 'time_employed']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the percentage of null values present in both variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employment       0.0611\n",
       "time_employed    0.0529\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null percentage for employment and time_employed\n",
    "peer_to_peer_df[['employment', 'time_employed']].isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage of nulls for both variables is practically the same. Now we can analyze the categories belonging to each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique employments: 12\n",
      "Unique employments: ['Teacher' 'Accountant' 'Statistician' 'Other' 'Bus driver' 'Secretary'\n",
      " 'Software developer' 'Nurse' 'Taxi driver' nan 'Civil Servant' 'Dentist']\n"
     ]
    }
   ],
   "source": [
    "# unique categories for both features - employment\n",
    "print(f'Number of unique employments:', len(peer_to_peer_df.employment.unique()))\n",
    "print(f'Unique employments:', peer_to_peer_df.employment.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time employed: ['<=5 years' '>5 years' nan]\n"
     ]
    }
   ],
   "source": [
    "# unique categories for both features - time_employed\n",
    "print(f'Time employed:', peer_to_peer_df.time_employed.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As both have the same percentage of nulls and have a relationship with each other, it is possible that the nulls present in `time_employed` are for individuals who do not have a job, since there is no way to fill the time employed - and these must consist of most nulls in the `employment` variable. We can check this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005325380764724678"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of those who declared employed but time_employed is null\n",
    "peer_to_peer_df[\n",
    "    ~peer_to_peer_df.employment.isnull()\n",
    "].time_employed.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8576104746317512"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of those who not declared employed and time_employed is null\n",
    "peer_to_peer_df[\n",
    "    peer_to_peer_df.employment.isnull()\n",
    "].time_employed.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is clear that the hypothesis we made - that the individuals who have null `time_employed` are, in their majority, those who have null `employment` - is correct. The case in which `time_employment` is null but `employment` is not, has a tiny percentage of the total nulls. This is a typical MAR case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Missing Data Not At Random (MNAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNAR is missing data whose absence concerns the variable itself due to some mechanism behind that causes the missing data. There are two variables from the Titanic dataset that are good candidates for this scenario, which are `age` and `cabin`. The idea is to check whether, in most cases where these variables have null values, the person in question did not survive - because in this case the data remains null. People who survived could have their data filled in these variables later. If this occurs, it is a typical case of MNAR - the absence of the value is directly linked to the `survived` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if in cases where `cabin` assumes null values, what is the percentage of people who survived and who did not survive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "0    0.873918\n",
       "1    0.614000\n",
       "Name: cabin, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of survivor vs non-survivor for those whose cabin is missing\n",
    "titanic_df.cabin.isnull().groupby(titanic_df['survived']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `survived` takes the value $1$ if the passenger survived and $0$ if he did not. The result shows us that $87\\%$ of non-survivors have `cabin` as null, against $61\\%$ in the case of survivors. Apparently this result supports our hypothesis. However, to conclude that this is indeed a MNAR, we would need to understand how this data was collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the analysis for the `age` variable. Again, let's look at the percentage of survivors and non-survivors for the case where the variable `age` takes null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "0    0.234858\n",
       "1    0.146000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of survivor vs non-survivor for those whose age is missing\n",
    "titanic_df.age.isnull().groupby(titanic_df['survived']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the same conclusion. People who did not survive have a greater number of nulls in the age variable. Apparently this is a systematic error, as we predicted. People who did not survive are more likely to have missing data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feature_engineering_for_machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
